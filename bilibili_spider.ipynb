{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "headers = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "           'Cache-Control': 'no-cache',\n",
    "           'Connection': 'keep-alive',\n",
    "           'User-Agent': 'Mozilla/6.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "\n",
    "proxies = {\n",
    "    \"http\": \"http://125.123.157.22:3000\",\n",
    "    \"https\": \"https://127.0.0.1:8080\",\n",
    "}\n",
    "\n",
    "#print(requests.validate(proxies))\n",
    "\n",
    "def get_page(url):\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        resp.encoding = 'utf-8'\n",
    "        print(resp)\n",
    "        #print(resp.text)\n",
    "        return resp\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置代理IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "enable_proxy = True\n",
    "proxy_handler = urllib.request.ProxyHandler({\"http\":'http://www.66ip.cn/'})\n",
    "null_proxy_handler = urllib.request.ProxyHandler({})\n",
    "if enable_proxy:\n",
    "    opener = urllib.request.build_opener(proxy_handler)\n",
    "else:\n",
    "    opener = urllib.request.build_opener(null_proxy_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "bili = \"https://www.bilibili.com\"\n",
    "\n",
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "bpage = get_page(bili)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_all_href(soup):\n",
    "    a_list = soup.find_all('a')\n",
    "    url_list = []\n",
    "    for a in a_list:\n",
    "        if a.attrs.get('href'):\n",
    "            #print(a.attrs.get('href'))\n",
    "            url_list.append(a.attrs.get('href'))\n",
    "    return url_list\n",
    "\n",
    "#urls = get_all_href(soup)\n",
    "\n",
    "def get_danmu(url):\n",
    "    #获取bv号\n",
    "    pattern = re.compile(r'BV([\\w]*)')\n",
    "    bv = \"BV\" + re.findall(pattern, url)[0]\n",
    "    print(bv)\n",
    "    cid = get_cid(bv)\n",
    "    if cid is None:\n",
    "        return None\n",
    "    dresp = get_danmu_xml(cid)\n",
    "    soup = BeautifulSoup(dresp.text)\n",
    "    danmu = soup.find_all('d')\n",
    "    return danmu\n",
    "    #write...\n",
    "    \n",
    "def get_cid(bv):\n",
    "    url = \"https://api.bilibili.com/x/player/pagelist?bvid=\" + bv + \"&jsonp=jsonp\"\n",
    "    resp = get_page(url)\n",
    "    if resp is None:\n",
    "        return None\n",
    "    csoup = BeautifulSoup(resp.text)\n",
    "    info = eval(str(csoup.string))\n",
    "    cid = info.get('data')[0].get('cid')\n",
    "    return cid\n",
    "    \n",
    "def get_danmu_xml(cid):\n",
    "    url = \"https://api.bilibili.com/x/v1/dm/list.so?oid=\"+str(cid)\n",
    "    #danmu_path = \"http://comment.bilibili.com/\"+str(cid)+\".xml\"\n",
    "    resp = get_page(url)\n",
    "    return resp\n",
    "\n",
    "def get_danmu_bytes(bv):\n",
    "    cid = get_cid(bv)\n",
    "    contents = get_danmu_xml(cid)\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "\n",
    "#d_list = get_danmu(\"https://www.bilibili.com/video/BV1p5411s7fF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d_contents(danmu):\n",
    "    dm = []\n",
    "    for d in danmu:\n",
    "        for c in d.contents:\n",
    "            #print(isinstance(c, bs4.element.Tag))\n",
    "            if(isinstance(c, bs4.element.NavigableString)):\n",
    "                dm.append(c.strip())\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "def set_proxies():\n",
    "    enable_proxy = True\n",
    "    proxy_handler = urllib.request.ProxyHandler({\"http\":'http://www.66ip.cn/areaindex_19/1.html'})\n",
    "    null_proxy_handler = urllib.request.ProxyHandler({})\n",
    "    if enable_proxy:\n",
    "        opener = urllib.request.build_opener(proxy_handler)\n",
    "    else:\n",
    "        opener = urllib.request.build_opener(null_proxy_handler)\n",
    "'''\n",
    "\n",
    "# root：爬虫起点url\n",
    "# path：抓取的弹幕文件存储位置\n",
    "def crawl(root, path, maximum=100):\n",
    "    urls = [root]\n",
    "    # path = 'Jerry'\n",
    "    visited = []\n",
    "    count = 0\n",
    "    if path not in os.listdir():\n",
    "        os.makedirs(path)\n",
    "    while len(urls)>0 and count<maximum:\n",
    "        #读取url\n",
    "        url = urls.pop(0)\n",
    "        \n",
    "        #已访问：跳过本次循环\n",
    "        if url in visited:\n",
    "            continue\n",
    "        # set_proxies()\n",
    "        _html = get_page(url)\n",
    "        #访问出错，跳过本次循环\n",
    "        if _html is None:\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        \n",
    "        _soup = BeautifulSoup(_html.text)\n",
    "        _html_p = _soup.prettify()\n",
    "        if _soup.title:\n",
    "            url_name = _soup.title.contents[0]\n",
    "        else:\n",
    "            continue\n",
    "            #url_name = 'nt'+ str(count)\n",
    "        \n",
    "        #获取下一层url\n",
    "        related = _soup.findAll(name=\"div\", attrs={\"class\" :\"recommend-list\"})\n",
    "        print(related)\n",
    "        rsoup = BeautifulSoup(str(related[0]))\n",
    "        r_list = rsoup.findAll(name=\"a\", attrs={\"class\": \"title\"})\n",
    "        print(r_list)\n",
    "        for r in r_list:\n",
    "            href = r.attrs.get('href')\n",
    "            urls.append(\"https://www.bilibili.com\" + href)\n",
    "        \n",
    "        #将当前url写入已遍历的visited数组中\n",
    "        visited.append(url)\n",
    "        \n",
    "        \n",
    "        #在相应文件目录下写入.html文件\n",
    "        # set_proxies()\n",
    "        danmu = get_danmu(url)\n",
    "        if danmu is None:\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        danmu = get_d_contents(danmu)\n",
    "        df = pd.DataFrame(danmu, columns=['danmu'])\n",
    "        \n",
    "        #print(df)\n",
    "        csv = os.path.join(path, url_name + '.csv')\n",
    "        try:\n",
    "            df.to_csv(csv, index=False, sep=',', encoding=\"utf_8_sig\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[<div class=\"recommend-list report-wrap-module report-scroll-module\" id=\"reco_list\"><!-- --><div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div><div class=\"loading-card\"><div class=\"cover\"></div><div class=\"info\"><p class=\"title\"></p><p class=\"up\"></p><p class=\"desc\"></p></div></div></div><div class=\"rec-footer\" style=\"display:none;\">展开</div></div>]\n",
      "[]\n",
      "BV1aJ411C7tb\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "crawl(\"https://www.bilibili.com/video/BV1aJ411C7tb\", 'digital', maximum=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     了    的    我    ，    吃  万州   是   吧   ？   。  ...  油太宽  女儿  别说  断  上新菜  摸  \\\n",
      "0  276  171  162  160  121  96  84  80  79  73  ...    1   1   1  1    1  1   \n",
      "\n",
      "   不齐  试试  方程式  68  \n",
      "0   1   1    1   1  \n",
      "\n",
      "[1 rows x 1289 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(series_list[0].to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
